{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa \n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet(r\"yellow_tripdata_2021-01.parquet\")\n",
    "\n",
    "pf = ParquetFile(r\"yellow_tripdata_2021-01.parquet\") \n",
    "first_N_rows = next(pf.iter_batches(batch_size = 10)) \n",
    "df = pa.Table.from_batches([first_N_rows]).to_pandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7fa0dad91130>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the engine to tell pandas how to create the connection with Postgres\n",
    "engine = create_engine(\"postgresql://root:root@localhost:5432/ny_taxi\")\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count FLOAT(53), \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" FLOAT(53), \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53), \n",
      "\tairport_fee FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name=\"yellow_taxi_data\", con=engine)) # DDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the table\n",
    "df.head(n=0).to_sql(name=\"yellow_taxi_data\", con=engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk..., took 17.63769245147705 seconds\n",
      "Inserted another chunk..., took 16.929617166519165 seconds\n",
      "Inserted another chunk..., took 17.269720792770386 seconds\n",
      "Inserted another chunk..., took 16.83879041671753 seconds\n",
      "Inserted another chunk..., took 17.601258277893066 seconds\n",
      "Inserted another chunk..., took 18.413028955459595 seconds\n",
      "Inserted another chunk..., took 18.07041096687317 seconds\n",
      "Inserted another chunk..., took 18.738840579986572 seconds\n",
      "Inserted another chunk..., took 19.214532136917114 seconds\n",
      "Inserted another chunk..., took 20.42062473297119 seconds\n",
      "Inserted another chunk..., took 20.528541564941406 seconds\n",
      "Inserted another chunk..., took 19.914849281311035 seconds\n",
      "Inserted another chunk..., took 20.32881474494934 seconds\n",
      "Inserted another chunk..., took 12.172627687454224 seconds\n"
     ]
    }
   ],
   "source": [
    "# Chunking a parquet file \n",
    "parquet_file = ParquetFile(\"yellow_tripdata_2021-01.parquet\")\n",
    "\n",
    "chunk_size = 100000\n",
    "for batch in parquet_file.iter_batches(batch_size=chunk_size):\n",
    "    t1 = time()\n",
    "    batch_df = batch.to_pandas()\n",
    "    # Add data to the table\n",
    "    batch_df.to_sql(name=\"yellow_taxi_data\", con=engine, if_exists=\"append\")\n",
    "    \n",
    "    t2 = time()\n",
    "\n",
    "    print(f\"Inserted another chunk..., took {t2-t1} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
